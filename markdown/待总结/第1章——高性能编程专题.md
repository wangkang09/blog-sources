[TOC]

# 0 预备课2

## 0.1 技术通用 3W1H 分析法

- What 技术是什么鬼
- Where 用在什么场景
- Why 为什么要用
- How 内部构造，原理

![./img/3W1H示例图.png](./img/3W1H示例图.png)



# 1 多线程并发编程

## 1.1 Java 基础



### 1.1.1 Java 程序运行原理分析

#### 1.1.1.1 class 文件内容

- class 文件包含 java 程序执行的字节码；数据严格按照格式紧凑排列在 class 文件中的二进制流，中间无任何分隔符；文件开头有一个 0xcafebabe 特殊的一个标志
- 通过 Javap 可以反编译

![](./img/class 文件内容.png)

- [class 内容反编译解析](./class文件内容反编译解析.md)

#### 1.1.1.2 JVM 运行时数据区

- 一般可分为五大部分：方法区、堆内存、虚拟机栈、本地方法栈、程序计数器
- 也可分为线程独占区、线程共享区
  - **线程独占：**每个线程都有独立的空间，随线程生命周期而创建和销毁
  - **线程共享：**所有线程都能访问这块内存数据，随虚拟机或者 GC 而创建和销毁

![](./img/JVM 运行时数据区.png)

**方法区**

- JVM 用来出错加载的类信息、常量、静态变量、编译后的代码等数据
- 方法区是一个逻辑区划。不同虚拟机实现可能不同。如：oracle 的 HotSpot 在 Java 7 中方法区放在（称为）永久代，Java 8 放在（称为）元数据空间，并通过 GC 机制对这个区域进行管理

**堆内存**

- 可细分为：老年代、新生代（Eden、From Survivor、To Survivor）
- 存放对象实例。垃圾回收器主要就是管理堆内存。
- 不同的垃圾回收器有不同的回收算法

**虚拟机栈**

- 每个线程都在虚拟机栈空间中有一个私有的空间，称为线程栈
- 线程栈有多个栈帧（Stack Frame）组成
- 一个线程会执行一个或多个方法，每执行一个方法就会创建一个栈帧
- 栈帧包括：局部变量表、操作数栈、动态链接、方法返回地址、附加信息等
- 栈内存默认最大为1M，超出则抛出 StackOverflowError

**本地方法栈**

- 和虚拟机栈类型，虚拟机栈是为虚拟机执行 Java 方法而准备的，本地方法栈是为虚拟机使用 Native 本地方法而准备的
- 不同的虚拟机厂商有不同的实现
- HotSpot 虚拟机中这两个实现是一样的。超出大小后抛出 StackOverflowError

**程序计数器**

- 基类当前线程执行字节码的位置，存储的是字节码指令地址，如果执行 Native 方法，则计数器值为空
- 每个线程都有一个私有的空间，占用内存空间很少
- 一个 CPU 同一时间，只会执行一条线程中的指令
- 因为 JVM 多线程会轮流切换并分配 CPU 执行时间的方式。为了线程切换后，需要通过程序计数器（因为每个线程都已经对应了唯一的栈地址，只要记住偏移即可）来恢复正确的执行位置（[上下文切换](https://www.jianshu.com/p/4393a4537eca)）

#### 1.1.1.3 程序完整运行分析

- 加载信息到方法区：1.7及以前称为永久代，1.8开始称为元数据空间
- JVM 创建线程来执行代码：在虚拟机栈(本地方法栈)、程序计数器内存区域中创建线程独立的空间

![](./img/程序完整运行分析.png)

- [程序完整运行分析](./class文件内容反编译解析.md)



### 1.1.2 线程状态

Java 语言定义了6中线程状态，任意一个时间点，一个线程只能有且只有其中的一种状态。

- New：线程尚未启动
- Runnable：可运行的线程状态（可能正在执行，也可能在等待 CPU 时间）
- Blocked：阻塞状态，等待一个排它锁。处于 synchronized 同步代码块或方法中被阻塞
- Waiting：无限等待状态，线程不会被分配 CPU 时间，需等待其他线程显示地唤醒
  - Object.wait()、Thread.join()、LockSupport.park()
- Time Waiting：有限等待状态，线程不会被分配 CPU 时间，一定时间后会**由系统自动唤醒**
  - Thread.sleep()、Object.wait(long)、Thread.join(long)、LockSupport.parkNanos()、LockSupport.parkUntil()
- Terminated：线程执行结束的状态

![](./img/线程状态.png)

### 1.1.3 线程中止

#### 1.1.3.1 不正确的线程中止 - Stop

- Stop：中止线程，**并清除监控器锁的信息**
- **可能导致线程安全问题**（同步代码块中的变量值也不一致了），JDK 不建议用
- Destory：JDK 为实现该方法

#### 1.1.3.2 正确的线程中止 - interrupt

- 如果目标程序在调用 wait(..)、join(..)、sleep(long,int)方法被阻塞时，调用 interrupt 会生效。该线程的中断状态将被清除，抛出 InterruptedException 异常
- 如果目标线程是被 I/O 或者 NIO 中的 Channel 所阻塞，同样，I/O 操作会被中断或返回特殊异常值。达到中止线程的目的
- 如果以上条件都不满足，则会设置此线程的状态为中断状态

#### 1.1.3.3 正确的线程中止 - 标志位

- 代码逻辑中增加一个判断，用来控制线程执行的终止（这个变量必须是同步的）

```java
public volatile static boolean flag = true;
while (flag) { // 判断是否运行
  System.out.println("运行中");
  Thread.sleep(1000L);
}
```



### 1.1.4 CPU 缓存和内存屏障

####   1.1.4.1 性能优化 - CPU 3级缓存

- 为了提高程序运行的性能，避免处理器访问主内存的时间开销，CPU 大多会利用缓存来提高性能
- L1 Cache(一级缓存)：分为 数据缓存 和 指令缓存。一般在 32-4096KB
- L2 Cache(二级缓存)：为了再次提高 CPU 运算速度，在 CPU 外部放置的高速存储器
- L3 Cache(三级缓存)：是多 CPU 共享的
- CPU 在读取数据时，先在 L1 中找，再从 L2 中找，再到 L3 中，然后在内存中，最后到外存中

![](./img/CPU 3级缓存.png)

#### 1.1.4.2 多 CPU 缓存一致性协议 - MESI

- 参考[CPU缓存一致性协议MESI](https://www.cnblogs.com/yanlong300/p/8986041.html)

- 多个 CPU 读取同一个地址数据后，进行不同的运算，如何**保证缓存内部数据的一致**,不让系统数据混乱。这里就引出了一个一致性的协议MESI 
- MESI 协议来保证一致性

| 状态                     | 描述                                                         | 监听任务                                                     |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| M 修改 (Modified)        | 该Cache line有效，数据被修改了，和内存中的**数据不一致**，**但数据只存在于本Cache中**。 | 缓存行必须时刻监听所有试图**读该缓存行相对与主存**的操作，其它读取操作，**必须等该cache 将数据载入主存**，并将缓存行修改为S后，才能执行 |
| E 独享、互斥 (Exclusive) | 该Cache line有效，数据和内存中的**数据一致**，**数据只存在于本Cache中**。 | 缓存行必须监听其它缓存**读主存中该缓存行的操作**，一旦有这种操作，该缓存行需要变成S（共享）状态 |
| S 共享 (Shared)          | 该Cache line有效，数据和内存中的**数据一致**，数据**存在于很多Cache中**。 | 缓存行必须监听其它缓存**使该缓存行无效或者独享该缓存行的请求**，并**将该缓存行变成无效**（Invalid） |
| I 无效 (Invalid)         | 该Cache line无效。                                           | 无                                                           |

- 如果一个缓存将处于S状态的缓存行作废了，而另一个缓存**实际上可能已经独享了该缓存行**，但是该缓存却不会将该缓存行升迁为E状态，这是**因为其它缓存不会广播他们作废掉该缓存行的通知**，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行

![](./img/MESI状态转换.png)

- 遇到远程写时，其它 CPU 的缓存行都变成无效状态
- 遇到远程读时，所有 CPU 的缓存行都变成共享状态
- 当前 CPU 本地写，不管当前什么状态，当前 CPU 的状态变为修改状态。其它 CPU 变成无效状态

#### 1.1.4.3 性能优化 - 运行时指令重排

- 当 CPU 写缓存时发现缓存区块正被其它 CPU 占用为了提高 CPU 处理性能，可能将后面的读取缓存指令优先执行
- **需要遵循 as-if-serial 语义**：指令重排后，不改变执行结果

![](./img/运行时指令重排.png)

#### 1.1.4.4 MESI和指令重排问题

**MESI 问题**

- 缓存的一致性消息传递需要时间，切换状态会产生延时，这会影响性能和稳定
- 虽然说加入了存储缓存，但是说是还是有问题（具体问题暂时没搞懂，以后有需求的时候在看吧）
- 所以最终引入了内存屏障

**指令重排问题**

- **as-if-serial 语义只保证在单个 CPU 自己执行的情况下能保证结果正确**
- 多核多线程中指令逻辑无法分辨因果关联，可能出现乱序执行，导致结果不一致

#### 1.1.4.5 解决方案 - 内存屏障

- 处理器提供了两个内存屏障指令（Memory Barrier）来解决上一小节的问题
  - **写内存屏障**（Store Memory Barrier）：在**指令后**插入写屏障，能让写入缓存中的最新数据更新入主存，让其他线程可见。这样强制写入主存，保证了 CPU 不会为性能而去指令重排
  - **读内存屏障**（Load Memory Barrier）：在**指令前**插入读屏障，可以让高速缓存中的数据失效，强制重新去主存中加载数据。这样强制读取主存，配合强制写入，就可以避免缓存一致性问题

### 1.1.5 [Java 内存模型](./Java 内存模型.md)

### 1.1.6 线程通信

- 文件共享：通过一个系统文件，如 xx.txt
- 网络共享：
- 共享变量：变量
- jdk 提供的线程协调 API：生产者与消费者

### 1.1.7 线程封闭 - ThreadLocal

### 1.1.8 线程池

**线程不是越多越好**

- 线程的创建和销毁需要时间，如果时间的执行时间很短，再去创建线程可能就没什么收益了（创建线程的时间里，任务已经执行完了）
- 线程的创建需要资源，java 对象占用堆内存，操作系统线程占用系统内存。一个线程默认最大栈大小为1M，线程过多，会消耗很多的内存
- 操作系统需要平方的**切换上下文**（详细介绍），影响性能

#### 1.1.8.1 线程池 API

| 类型   | 名称                        | 描述                                                         |
| ------ | --------------------------- | ------------------------------------------------------------ |
| 接口   | Executor                    | 最上层的接口，定义了执行任务的方法 execute                   |
| 接口   | ExecutorService             | 继承了 Executor 接口，扩展了 Callable、Future、关闭方法      |
| 接口   | ScheduledExecutorService    | 继承了ExecutorService，增加了定时任务相关方法                |
| 实现类 | ThreadPoolExecutor          | 基础、标准的线程池实现                                       |
| 实现类 | ScheduledThreadPoolExecutor | 继承了 ThreadPoolExecutor，实现了ScheduledExecutorService中相关定时任务方法 |

#### 1.1.8.2 ThreadPoolExecutor 类解析

- ThreadPoolExecutor 最核心构造方法

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {}
```

- 构造方法参数说明

| 参数名                   | 作用                                                         |
| ------------------------ | ------------------------------------------------------------ |
| corePoolSize             | 核心线程池大小                                               |
| maximumPoolSize          | 最大线程池大小                                               |
| keepAliveTime            | 线程池中超过corePoolSize数目的**空闲线程**最大存活时间；可以allowCoreThreadTimeOut(true)使得核心线程有效时间 |
| TimeUnit                 | keepAliveTime时间单位                                        |
| workQueue                | 阻塞任务队列                                                 |
| threadFactory            | 新建线程工厂                                                 |
| RejectedExecutionHandler | 拒绝策略，当提交任务数超过maxmumPoolSize+workQueue之和时，任务会交给RejectedExecutionHandler来处理，如下图 |

#### 1.1.8.3 线程池执行过程

![](./img/线程池执行过程.png)



#### 1.1.8.3 Executors 工具类解析

## 1.2 线程安全问题

### 1.2.1 线程安全之可见性问题

#### 1.2.1.1 指令重排序和缓存导致的问题

- 缓存问题是不同步的因素之一
- 指令重排也是不同步的因素之一，但它主要是造成无限循环程序（同步之后也不能退出循环！）

```java
// 1、 jre/bin/server  放置hsdis动态链接库
//  测试代码 将运行模式设置为-server， 变成死循环   。 没加默认就是client模式，就是正常（可见性问题）
// 2、 通过设置JVM的参数，打印出jit编译的内容 （这里说的编译非class文件），通过可视化工具jitwatch进行查看
// -server -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:+LogCompilation -XX:LogFile=jit.log
//  关闭jit优化-Djava.compiler=NONE,这个之后就能打印了，说明了 jit 进行了优化处理导致无限循环
public class VisibilityDemo {
    // 运行标志
    public boolean flag = true;

    // JIT just in time ( --  --)
    public static void main(String[] args) throws InterruptedException {
        VisibilityDemo demo1 = new VisibilityDemo();
        System.out.println("代码开始了");
        Thread thread1 = new Thread(new Runnable() {
            public void run() {
                int i = 0;
                //进行了如下的指令重排序
//                boolean f = demo1.flag;
//                if(f) {
//                    while(true){
//                        i++;
//                    }
//                }
                while (demo1.flag) {
                        i++;
                }
                System.out.println(i);
            }
        });
        thread1.start();

        TimeUnit.SECONDS.sleep(2);
        // 设置is为false，使上面的线程结束while循环
        demo1.flag = false;
        System.out.println("被置为false了.");
    }
}
```



#### 1.2.1.2 脚本语言与编译语言

- **脚本语言：**解释执行，在执行时，由语言的解释器将其一条条翻译成机器码可识别的指令（翻译一条，执行一条）
- **编译语言：**将我们编译的程序，批量编译成机器可识别的指令码（翻译所有，一起执行）

#### 1.2.1.3 什么是 JIT 编译器(Just In Time Compiler)

![](./img/JIT示意图.png)



#### 1.2.1.4 final在 JMM 中的处理

![](./img/final在 JMM 中的处理.png)



- final 在**构造函数**中赋的值，对其它线程同步

#### 1.2.1.5 同步规则定义

![](./img/同步规则的定义.png)

- 线程状态变化是同步的

![](./img/线程状态变化是同步的.png)

#### 1.2.1.6 先行发生原则

![](./img/先行发生原则.png)

#### 1.2.1.7 字节分裂问题

![](./img/字节分裂.png)



### 1.2.2 线程安全之原子性操作

#### 1.2.2.1 JUC 原子操作封装类

![](./img/JUC原子操作封装类.png)

### 1.2.3 Java 锁

synchronized是Java內建的同步机制，它提供了一种独占的加锁方法，用户不需要显示的释放锁，保证了线程安全。

- 作用于方法上时，锁住的是对象实例
- 作用于静态方法时，锁住的是类实例
- 作用于某一object对象时，锁住的是object对象实例

`synchronized`、`wait`、`notify` 操作的必须是同一个对象

#### 1.2.3.0 对象头部信息

- Class Meta address：对象的元数据，通过这个区分堆中的类是那个实例
- Array length：如果对象是个数组，通过这个属性来表示数组的长度

![](./img/对象头部信息.png)

#### 1.2.3.1 轻量级锁

![](./img/轻量级锁.png)

#### 1.2.3.2 重量级锁

- 重量级锁是通过 监视器实现的
- 每个对象都会对应一个监视器
- 监视器中有 owner、entyList、waitSet 等属性，来控制多线程的执行！

![](./img/重量级锁.png)

#### 1.2.3.3 偏向锁

![](./img/偏向锁.png)

#### 1.2.3.4 锁升级过程

![](./img/锁升级过程.png)

#### 1.2.3.5 监视器详情

![](./img/监视器详情.png)

## 1.3 JUC 并发编程包详解

### 1.3.1 Lock 接口



### 1.3.2 map

HashMap：单线程

HashTable：多线程安全，但是锁粒度很大

ConcurrentHashMap：多线程安全，锁粒度小

TreeMap：有序的 map，内部采用红黑树，单线程

ConcurrentSkipListMap：有序 map，内部采用跳表，多线程安全

### 1.3.3 list

copyOnwriteArrayList：读多写少，线程安全

### 1.3.4 set

- set 和 list 重要区别：不重复

hashset：线程不安全，无序

copyOnwriteArraySet：线程安全，无序。基于 CopyOnWriteArrayList：addIfAbsent()

ConcurrentSkipListSet：线程安全，有序，查询快

### 1.3.5 queue

![](./img/Queue API.png)

- ArrayBlockingQueue
- LinkedBlockingQueue
- ConcurrentLinkedQueue
- SynchronousQueue：
  - take 会阻塞，直到取到元素
  - put 会阻塞，直到被get
  - 若没有 take 方法阻塞等待， offer 的元素可能会丢失
  - poll 取不到元素，就返回 null，如果真好有 Put 被阻塞，可以取到
  - peek 永远只能取到 null，不能让 take 结束阻塞
- PriorityBLockingQueue：

### 1.3.6 Fork/Join 框架

#### 1.3.6.1 CountDownLatch

# 2 高并发网络编程

## 2.1 Java NIO 网络编程

### 2.1.1 TCP/UDP 协议

#### 2.1.1.1 OSI 网络七层模型

![](./img/OSI 网络七层模型.png)

#### 2.1.1.2 7层主要功能

![](./img/7层主要功能.png)

#### 2.1.1.3 TCP 格式分析

![](./img/TCP 格式.png)



#### 2.1.1.4 UDP 格式

![](./img/UDP 格式.png)

#### 2.1.1.5 UDP 和 TCP 的比较

![](./img/UDP TCP 的比较.png)

### 2.1.2 BIO 阻塞式网络编程

#### 2.1.2.1 socket 编程

![](./img/socket 编程.png)

#### 2.1.2.2 HTTP 请求数据包解析

![](./img/HTTP 请求数据包解析.png)

#### 2.1.2.3 HTTP 响应数据包解析

![](./img/HTTP 响应数据包解析.png)

#### 2.1.2.4 HTTP 响应状态码

![](./img/HTTP 响应状态码.png)

#### 2.1.2.5 阻塞 IO 的含义

![](./img/阻塞 IO 的含义.png)

### 2.1.3 NIO 非阻塞网络编程

#### 2.1.3.1 NIO 3个核心组件

![](./img/JAVA NIO.png)



#### 2.1.3.2 Buffer 分析

##### 2.1.3.2.1 Buffer 3个重要属性

![](./img/Buffer 工作原理.png)

##### 2.1.3.2.2 Buffer 工作原理

![](./img/Buffer 缓冲区.png)

#### 2.1.3.2.2 ByteBuffer  内存类型

![](./img/ByteBuffer 内存类型.png)

#### 2.1.3.3 Channel 通道概念

![](./img/channel 通道.png)

##### 2.1.3.3.1 SocketChannel 

![](./img/SocketChannel.png)

##### 2.1.3.3.2 ServerSocketChannel

![](./img/ServerSocketChannel.png)

#### 2.1.3.4 Selector 分析

##### 2.1.3.4.1 Selector 选择器 功能

![](./img/Selector 选择器 功能.png)

##### 2.1.3.4.2 Selector 选择器 原理

![](./img/Selector 选择器 原理.png)

#### 2.1.3.5 NIO 与 BIO 比较

![](./img/NIO 对比 BIO.png)

#### 2.1.3.6 NIO 与多线程结合的改进方案

![](./img/NIO 与 多线程结合的改进方案.png)

## 2.2 Netty 框架分析

### 2.2.1 Netty 线程模型

#### 2.2.1.1 Netty 简介与 4个重要组成

![](./img/netty 简介.png)

#### 2.2.1.2 Netty 整体结构图

![](./img/netty 整体结构图.png)

#### 2.2.1.3 Netty  Reactor 线程模型

![](./img/netty 线程模型.png)

#### 2.2.1.4 EventLoopGroup 初始化过程

![](./img/EventLoopGroup 初始化过程.png)

#### 2.2.1.5 bind 绑定端口过程

![](./img/bind 绑定端口过程.png)

#### 2.2.1.6 channel 概念

![](./img/channel 概念.png)

#### 2.2.1.7 eventLoop 的启动

![](./img/eventLoop 的启动.png)

### 2.2.2 Netty 责任链分析

#### 2.2.2.1 Netty 的责任链 ChannelPipeline

![](./img/netty ChannelPipeline.png)

#### 2.2.2.2 入站事件出站事件

![](./img/入站事件出站事件.png)

#### 2.2.2.3 netty 中的事件

![](./img/netty 中的事件.png)

#### 2.2.2.4 pipeline 中的 handler 是什么

![](./img/pipeline 中的 handler 是什么.png)

#### 2.2.2.5 维护 pipeline 中的 handler

![](./img/维护 pipeline 中的 handler.png)

#### 2.2.2.6 handler 的执行分析

![](./img/handler 的执行分析.png)

#### 2.2.2.7 registered 入站事件处理

![](./img/registered 入站事件处理.png)

#### 2.2.2.8 bind 出站事件处理

![](./img/bind 出站事件处理.png)

#### 2.2.2.9 accept 入站事件处理

![](./img/accept 入站事件处理.png)

#### 2.2.2.10 read 入站事件处理

![](./img/read 入站事件处理.png)

#### 2.2.2.11 小结

![](./img/小结.png)

### 2.2.3 零拷贝机制

#### 2.2.3.1 ByteBuf 简介

![](./img/Netty ByteBuf.png)

#### 2.2.3.2 Netty ByteBuf 增强地方

![](./img/Netty ByteBuf 增强地方.png)

#### 2.2.3.3 Netty ByteBuf 方法定义

![](./img/Netty ByteBuf 方法定义.png)

#### 2.2.3.4 ByteBuf 三个区域

![](./img/ByteBuf 三个区域.png)

#### 2.2.3.5 byteBuf 动态扩容

![](./img/byteBuf 动态扩容.png)

#### 2.2.3.6 byteBuf 8种具体实现

![](./img/byteBuf 8种具体实现.png)

#### 2.2.3.7 unsafe 实现

![](./img/unsafe 实现.png)

#### 2.2.3.8 PooledByteBuf 对象及内存复用

![](./img/PooledByteBuf 对象及内存复用.png)

#### 2.2.3.9 零拷贝机制

![](./img/零拷贝机制.png)

### 2.2.4 拆包粘包

![](./img/粘包拆包.png)

### 2.2.5 [Netty 百万连接配置](./doc/netty-百万连接配置.md)

# 3 java 系统性能调优

## 3.1 JVM 性能调优

### 3.1.1 类加载机制

#### 3.1.1.1 类生命周期

![](./img/类生命周期.png)

#### 3.1.1.2 类加载器

![](./img/类加载器.png)

![](./img/类加载器0.png)

#### 3.1.1.3 class 信息位置

![](./img/类在哪里.png)

#### 3.1.1.4 类的加载和卸载

![](./img/类不会重复加载.png)

![](./img/类的卸载条件.png)

#### 3.1.1.5 双亲委派模型

![](./img/双亲委派模型.png)

### 3.1.2 垃圾回收机制

#### 3.1.2.1 回收前先标记

![](./img/回收前先标记.png)

#### 3.1.2.2 可达性分析算法

![](./img/可达性分析算法.png)

#### 3.1.2.3 4种引用类型与可达性级别

![](./img/4种引用类型.png)

#### 3.1.2.4 垃圾收集算法

![](./img/垃圾收集算法.png)

![](./img/分代收集.png)

![](./img/老年代.png)

#### 3.1.2.4 垃圾收集器

![](./img/串行收集器.png)

![](./img/并行收集器.png)

![](./img/并发收集器.png)

![](./img/并行收集器New.png)

![](./img/G1.png)

![](./img/垃圾收集器组合.png)

### 3.1.3 JDK 内置命令工具

#### 3.1.3.1 javap 反编译

![](./img/javap.png)

#### 3.1.3.2 jps jvm 参数监控

![](./img/jps.png)

#### 3.1.3.3 jstat jvm 内存（gc）监控

![](./img/jstat.png)

![](./img/jstat1.png)

#### 3.1.3.4 jcmd jps 替代 

![](./img/jcmd.png)

#### 3.1.3.5 jinfo 运行中 jvm 全部参数

![](./img/jinfo.png)

#### 3.1.3.6 jhat java 堆分析命令

![](./img/jhat.png)

#### 3.1.3.7 jmap 打印 堆中的 java 对象信息

![](./img/jmap.png)

#### 3.1.3.8 jstack java 栈信息 分析死锁 cpu 高的情况

![](./img/jstack.png)

#### 3.1.3.9 可视化工具 Jconsole

![](./img/jconsole.png)

#### 3.1.3.10 可视化工具 jvisualVM

![](./img/jvisualVM.png)

#### 3.1.3.11 实操

```cmd
// 查看 jvm 对应pid
jps 
// 生成 二进制文件
jmap -dump:live,file=D:heap.bin pid
// 通过 网页查看 文件内容
jhat -port 8080 D:heap.bin
// 通过 jvirsualVM 查看 文件内容
```

## 3.2 性能调优综合实践

### 3.2.1 JVM 参数及调优

#### 3.2.1.1 调优基本概念

![](./img/调优基本概念.png)

#### 3.2.1.2 JVM 常用参数

![](./img/jvm 常用参数.png)

#### 3.2.1.3 GC 调优思路

![](./img/GC 调优思路.png)

#### 3.2.1.4 通用 GC 参数

![](./img/通用 GC 参数.png)

#### 3.2.1.5 CMS 参数调优

![](./img/cms 调优.png)

#### 3.2.1.6 g1 参数调优

![](./img/g1 参数调优.png)

![](./img/JIT 调优.png)

### 3.2.2 Tomcat 网络处理线程模型

#### 3.2.2.1 BIO + 同步servlet

![](./img/BIO同步Servelt.png)

#### 3.2.2.2 APR + 异步Servlet

![](./img/APR异步Servlet.png)

#### 3.2.2.3 NIO + 异步servlet

![](./img/NIO异步Servlet.png)



#### 3.2.2.4 NIO 处理流程

![](./img/NIO处理流程.png)

### 3.2.3 Tomcat 参数调优

#### 3.2.3.1 参数调优

![](./img/Tomcat 参数.png)

#### 3.2.3.2 整体架构

![](./img/整体架构.png)

#### 3.2.3.3 [Tomcat 调优过程记录](./doc/tomcat调优过程记录.pdf)

### 3.2.4 [内存线上问题分析](./doc/直播笔记-1.docx)

### 3.2.5 CPU 线上问题分析

![](./img/cpu 线上问题.png)



